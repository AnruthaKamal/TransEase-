{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Machice Translation  (English to Hindi)**","metadata":{}},{"cell_type":"markdown","source":"# Import Library ","metadata":{}},{"cell_type":"code","source":"pip install transformers datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T08:13:36.826710Z","iopub.execute_input":"2024-06-03T08:13:36.827087Z","iopub.status.idle":"2024-06-03T08:13:41.064768Z","shell.execute_reply.started":"2024-06-03T08:13:36.827057Z","shell.execute_reply":"2024-06-03T08:13:41.063210Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\n\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import MarianMTModel, MarianTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-03T12:00:39.645645Z","iopub.execute_input":"2024-06-03T12:00:39.645976Z","iopub.status.idle":"2024-06-03T12:00:39.650660Z","shell.execute_reply.started":"2024-06-03T12:00:39.645949Z","shell.execute_reply":"2024-06-03T12:00:39.649645Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:12:26.214162Z","iopub.execute_input":"2024-06-03T17:12:26.214548Z","iopub.status.idle":"2024-06-03T17:12:26.220228Z","shell.execute_reply.started":"2024-06-03T17:12:26.214518Z","shell.execute_reply":"2024-06-03T17:12:26.219061Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# load dataset ","metadata":{}},{"cell_type":"code","source":"# Load the IITB English-Hindi dataset\ndataset = load_dataset(\"cfilt/iitb-english-hindi\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T12:02:00.641485Z","iopub.execute_input":"2024-06-03T12:02:00.642368Z","iopub.status.idle":"2024-06-03T12:02:06.461238Z","shell.execute_reply.started":"2024-06-03T12:02:00.642335Z","shell.execute_reply":"2024-06-03T12:02:06.460492Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/3.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172d906e377443de892f990db93d8189"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c250cb6b4c743ea9b767861904c2f96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/190M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86ed542cbb4c479ea55d3c6234c69550"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/85.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff7bfc5faefd4f1e8f021b58588231d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f4cdf8b5e75445bb66365b49afe2968"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1659083 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86720a999c9743da9956215d0f422633"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36705cef9aa1495aaece99454a8f1259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21196460a5a44cb8bbdafbb04cc02ac0"}},"metadata":{}}]},{"cell_type":"code","source":"dataset['train']","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:10:04.294913Z","iopub.execute_input":"2024-06-03T17:10:04.295644Z","iopub.status.idle":"2024-06-03T17:10:04.303274Z","shell.execute_reply.started":"2024-06-03T17:10:04.295613Z","shell.execute_reply":"2024-06-03T17:10:04.302329Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['translation'],\n    num_rows: 1659083\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(dataset['train']['translation'][0])","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:15:08.939448Z","iopub.execute_input":"2024-06-03T17:15:08.940098Z","iopub.status.idle":"2024-06-03T17:15:24.167317Z","shell.execute_reply.started":"2024-06-03T17:15:08.940069Z","shell.execute_reply":"2024-06-03T17:15:24.166170Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"{'en': 'Give your application an accessibility workout', 'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.DataFrame(dataset['train'].select(range(5)))\nprint(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:12:54.910795Z","iopub.execute_input":"2024-06-03T17:12:54.911568Z","iopub.status.idle":"2024-06-03T17:12:54.926525Z","shell.execute_reply.started":"2024-06-03T17:12:54.911539Z","shell.execute_reply":"2024-06-03T17:12:54.925469Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"                                         translation\n0  {'en': 'A black box in your car?', 'hi': 'आपकी...\n1  {'en': 'As America's road planners struggle to...\n2  {'en': 'The devices, which track every mile a ...\n3  {'en': 'The usually dull arena of highway plan...\n4  {'en': 'Libertarians have joined environmental...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# load Pre trained Model ","metadata":{}},{"cell_type":"code","source":"model_name = 'Helsinki-NLP/opus-mt-en-hi'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel = MarianMTModel.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T12:00:46.492163Z","iopub.execute_input":"2024-06-03T12:00:46.493034Z","iopub.status.idle":"2024-06-03T12:00:53.080744Z","shell.execute_reply.started":"2024-06-03T12:00:46.493003Z","shell.execute_reply":"2024-06-03T12:00:53.079841Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09cc0d905674432888710bef6bf8fd8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f55c0becf444e24a1bd4417d3c96e58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d21babcf9e4e19a21a5d405da16368"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a90b10a69f054c87936e0ca451eb27db"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73e6c77bad54244b6027300e710cbd0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/306M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3708db2a8beb4238a5fdb80a6d3eace8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f797577ddb84df799483e7105284c11"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Preprocessing ","metadata":{}},{"cell_type":"code","source":"max_length = 128\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T12:00:59.768954Z","iopub.execute_input":"2024-06-03T12:00:59.769709Z","iopub.status.idle":"2024-06-03T12:00:59.773778Z","shell.execute_reply.started":"2024-06-03T12:00:59.769679Z","shell.execute_reply":"2024-06-03T12:00:59.772758Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [ex[\"en\"].lower() for ex in examples[\"translation\"]]\n    targets = [ex[\"hi\"] for ex in examples[\"translation\"]]\n\n    model_inputs = tokenizer(inputs, max_length=max_length, truncation=True, padding=True)\n\n    # Tokenize and pad targets\n    tokenized_targets = tokenizer(\n        targets,\n        max_length=max_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\"  # Return PyTorch tensors\n    )\n    model_inputs[\"labels\"] = tokenized_targets[\"input_ids\"]\n\n    return model_inputs\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:14:09.602938Z","iopub.execute_input":"2024-06-03T17:14:09.603304Z","iopub.status.idle":"2024-06-03T17:14:09.612368Z","shell.execute_reply.started":"2024-06-03T17:14:09.603265Z","shell.execute_reply":"2024-06-03T17:14:09.611337Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets_validation = dataset['validation'].map(\n    preprocess_function,\n    batched= True,\n    remove_columns=dataset[\"validation\"].column_names,\n    batch_size = 2\n)\n \ntokenized_datasets_test = dataset['test'].map(\n    preprocess_function,\n    batched= True,\n    remove_columns=dataset[\"test\"].column_names,\n    batch_size = 2)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:14:14.091587Z","iopub.execute_input":"2024-06-03T17:14:14.092445Z","iopub.status.idle":"2024-06-03T17:14:20.579227Z","shell.execute_reply.started":"2024-06-03T17:14:14.092411Z","shell.execute_reply":"2024-06-03T17:14:20.578139Z"},"trusted":true},"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a60d093d4634299a39f7f2c3dc9c90b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c080177b3cd142cb86e3cb5c526bb110"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_train_sampled = dataset['train'].shuffle(seed=42).select(range(10000))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:14:26.753618Z","iopub.execute_input":"2024-06-03T17:14:26.754208Z","iopub.status.idle":"2024-06-03T17:14:26.788556Z","shell.execute_reply.started":"2024-06-03T17:14:26.754177Z","shell.execute_reply":"2024-06-03T17:14:26.787609Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets_train = dataset_train_sampled.map(\n    preprocess_function,\n    batched=True,\n    remove_columns=dataset[\"train\"].column_names,\n    batch_size=2\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T17:14:31.292394Z","iopub.execute_input":"2024-06-03T17:14:31.292754Z","iopub.status.idle":"2024-06-03T17:14:44.840886Z","shell.execute_reply.started":"2024-06-03T17:14:31.292729Z","shell.execute_reply":"2024-06-03T17:14:44.839673Z"},"trusted":true},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45325f03a7164e2685147845b507dd5f"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    eval_strategy='epoch',\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=100,\n    predict_with_generate=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T12:18:11.702419Z","iopub.execute_input":"2024-06-03T12:18:11.702782Z","iopub.status.idle":"2024-06-03T12:18:11.733130Z","shell.execute_reply.started":"2024-06-03T12:18:11.702755Z","shell.execute_reply":"2024-06-03T12:18:11.732184Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T12:18:14.447080Z","iopub.execute_input":"2024-06-03T12:18:14.447461Z","iopub.status.idle":"2024-06-03T12:18:16.873899Z","shell.execute_reply.started":"2024-06-03T12:18:14.447433Z","shell.execute_reply":"2024-06-03T12:18:16.872795Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets_train,\n    eval_dataset=tokenized_datasets_validation,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T12:18:19.774867Z","iopub.execute_input":"2024-06-03T12:18:19.775763Z","iopub.status.idle":"2024-06-03T12:18:19.876674Z","shell.execute_reply.started":"2024-06-03T12:18:19.775727Z","shell.execute_reply":"2024-06-03T12:18:19.875661Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T12:18:23.258879Z","iopub.execute_input":"2024-06-03T12:18:23.259715Z","iopub.status.idle":"2024-06-03T16:07:32.261230Z","shell.execute_reply.started":"2024-06-03T12:18:23.259682Z","shell.execute_reply":"2024-06-03T16:07:32.260051Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='62500' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [62500/62500 3:49:08, Epoch 100/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.424700</td>\n      <td>1.472495</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.029500</td>\n      <td>1.367169</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.960800</td>\n      <td>1.315711</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.868200</td>\n      <td>1.271148</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.822800</td>\n      <td>1.239563</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.798200</td>\n      <td>1.214833</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.776300</td>\n      <td>1.197706</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.715800</td>\n      <td>1.179995</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.691500</td>\n      <td>1.167351</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.670700</td>\n      <td>1.160036</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.657700</td>\n      <td>1.151133</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.617800</td>\n      <td>1.148241</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.596100</td>\n      <td>1.149410</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.573000</td>\n      <td>1.145154</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.572500</td>\n      <td>1.147565</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.530300</td>\n      <td>1.145801</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.513400</td>\n      <td>1.151283</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.501400</td>\n      <td>1.158045</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.495800</td>\n      <td>1.156871</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.467800</td>\n      <td>1.169966</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.446500</td>\n      <td>1.175918</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.439400</td>\n      <td>1.176686</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.430200</td>\n      <td>1.192163</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.409500</td>\n      <td>1.194273</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.393100</td>\n      <td>1.200441</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.385400</td>\n      <td>1.213231</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.376700</td>\n      <td>1.219832</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.360200</td>\n      <td>1.234901</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.346300</td>\n      <td>1.240387</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.336700</td>\n      <td>1.254139</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.339500</td>\n      <td>1.258317</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.319400</td>\n      <td>1.273945</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.307400</td>\n      <td>1.285420</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.296100</td>\n      <td>1.296590</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.297100</td>\n      <td>1.306405</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.279700</td>\n      <td>1.317426</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.273500</td>\n      <td>1.328206</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.264300</td>\n      <td>1.343582</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.262200</td>\n      <td>1.355829</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.251300</td>\n      <td>1.369798</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.241800</td>\n      <td>1.376097</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.236500</td>\n      <td>1.385959</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.232800</td>\n      <td>1.397919</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.222600</td>\n      <td>1.417758</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.217100</td>\n      <td>1.432173</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.213800</td>\n      <td>1.438490</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.206200</td>\n      <td>1.449591</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.201700</td>\n      <td>1.454112</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.191700</td>\n      <td>1.471221</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.192400</td>\n      <td>1.472183</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.190300</td>\n      <td>1.495127</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.181800</td>\n      <td>1.505278</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.175600</td>\n      <td>1.510120</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.174100</td>\n      <td>1.524773</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.171400</td>\n      <td>1.531026</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.163800</td>\n      <td>1.541418</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.159200</td>\n      <td>1.565958</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.157300</td>\n      <td>1.565398</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.156400</td>\n      <td>1.569901</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.149700</td>\n      <td>1.582170</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>0.148100</td>\n      <td>1.592872</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.143200</td>\n      <td>1.596609</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.142900</td>\n      <td>1.607430</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.138900</td>\n      <td>1.617701</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.134500</td>\n      <td>1.614355</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.131700</td>\n      <td>1.629428</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.134300</td>\n      <td>1.635698</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.127600</td>\n      <td>1.646425</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.125800</td>\n      <td>1.652522</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.123900</td>\n      <td>1.662340</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.121300</td>\n      <td>1.667609</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.119000</td>\n      <td>1.666800</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.117700</td>\n      <td>1.676526</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.116700</td>\n      <td>1.686322</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.113900</td>\n      <td>1.691917</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.113400</td>\n      <td>1.698167</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.109500</td>\n      <td>1.701061</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.109200</td>\n      <td>1.705024</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.111000</td>\n      <td>1.708589</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.106600</td>\n      <td>1.723067</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.105300</td>\n      <td>1.719065</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.103200</td>\n      <td>1.721236</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.102500</td>\n      <td>1.728995</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.101400</td>\n      <td>1.730659</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.099900</td>\n      <td>1.738116</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.100400</td>\n      <td>1.740806</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.099400</td>\n      <td>1.746233</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.097100</td>\n      <td>1.751060</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.095500</td>\n      <td>1.753976</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.094900</td>\n      <td>1.753338</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.095500</td>\n      <td>1.761328</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.095400</td>\n      <td>1.762678</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.093900</td>\n      <td>1.763053</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.093600</td>\n      <td>1.762489</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.091500</td>\n      <td>1.764545</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.092400</td>\n      <td>1.765103</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.090900</td>\n      <td>1.766174</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.092500</td>\n      <td>1.767009</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.092700</td>\n      <td>1.767650</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.091100</td>\n      <td>1.767880</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=62500, training_loss=0.2906491841430664, metrics={'train_runtime': 13748.4972, 'train_samples_per_second': 72.735, 'train_steps_per_second': 4.546, 'total_flos': 2.032227316452557e+16, 'train_loss': 0.2906491841430664, 'epoch': 100.0})"},"metadata":{}}]},{"cell_type":"code","source":"results = trainer.evaluate(eval_dataset=tokenized_datasets_test)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:07:44.407448Z","iopub.execute_input":"2024-06-03T16:07:44.408176Z","iopub.status.idle":"2024-06-03T16:07:52.846831Z","shell.execute_reply.started":"2024-06-03T16:07:44.408147Z","shell.execute_reply":"2024-06-03T16:07:52.845839Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [157/157 00:08]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 2.0474207401275635, 'eval_runtime': 8.4217, 'eval_samples_per_second': 297.682, 'eval_steps_per_second': 18.642, 'epoch': 100.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained('./fine-tuned-marianmt-en-hi')\ntokenizer.save_pretrained('./fine-tuned-marianmt-en-hi')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:08:02.887210Z","iopub.execute_input":"2024-06-03T16:08:02.887950Z","iopub.status.idle":"2024-06-03T16:08:03.761998Z","shell.execute_reply.started":"2024-06-03T16:08:02.887919Z","shell.execute_reply":"2024-06-03T16:08:03.760724Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]], 'forced_eos_token_id': 0}\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"('./fine-tuned-marianmt-en-hi/tokenizer_config.json',\n './fine-tuned-marianmt-en-hi/special_tokens_map.json',\n './fine-tuned-marianmt-en-hi/vocab.json',\n './fine-tuned-marianmt-en-hi/source.spm',\n './fine-tuned-marianmt-en-hi/target.spm',\n './fine-tuned-marianmt-en-hi/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import MarianMTModel, MarianTokenizer\n\n# Load the fine-tuned model and tokenizer\nmodel_name = './fine-tuned-marianmt-en-hi'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\nmodel_test = MarianMTModel.from_pretrained(model_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:08:14.664357Z","iopub.execute_input":"2024-06-03T16:08:14.665594Z","iopub.status.idle":"2024-06-03T16:08:16.660048Z","shell.execute_reply.started":"2024-06-03T16:08:14.665561Z","shell.execute_reply":"2024-06-03T16:08:16.658931Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prepare test sentences\ntest_sentences = [\n    \"What is your name?\",\n    \"I loved the movie.\",\n    \"How are you?\",\n    \"This is a test sentence for translation.\",\n]\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:08:32.235367Z","iopub.execute_input":"2024-06-03T16:08:32.236080Z","iopub.status.idle":"2024-06-03T16:08:32.241624Z","shell.execute_reply.started":"2024-06-03T16:08:32.236053Z","shell.execute_reply":"2024-06-03T16:08:32.240501Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Tokenize the test sentences\ninputs = tokenizer(test_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:08:35.938594Z","iopub.execute_input":"2024-06-03T16:08:35.939015Z","iopub.status.idle":"2024-06-03T16:08:35.946810Z","shell.execute_reply.started":"2024-06-03T16:08:35.938988Z","shell.execute_reply":"2024-06-03T16:08:35.945798Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Generate translations\ntranslated_tokens = model_test.generate(**inputs)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:08:41.143285Z","iopub.execute_input":"2024-06-03T16:08:41.143682Z","iopub.status.idle":"2024-06-03T16:08:44.325285Z","shell.execute_reply.started":"2024-06-03T16:08:41.143655Z","shell.execute_reply":"2024-06-03T16:08:44.324133Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Decode the translations\ntranslated_sentences = [tokenizer.decode(t, skip_special_tokens=True) for t in translated_tokens]\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:08:48.091890Z","iopub.execute_input":"2024-06-03T16:08:48.092253Z","iopub.status.idle":"2024-06-03T16:08:48.106370Z","shell.execute_reply.started":"2024-06-03T16:08:48.092225Z","shell.execute_reply":"2024-06-03T16:08:48.105229Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Print the results\nfor original, translated in zip(test_sentences, translated_sentences):\n    print(f\"Original: {original}\")\n    print(f\"Translated: {translated}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:08:52.288310Z","iopub.execute_input":"2024-06-03T16:08:52.289107Z","iopub.status.idle":"2024-06-03T16:08:52.300172Z","shell.execute_reply.started":"2024-06-03T16:08:52.289076Z","shell.execute_reply":"2024-06-03T16:08:52.298355Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Original: What is your name?\nTranslated: तुम्हारा नाम क्या है?\n\nOriginal: I loved the movie.\nTranslated: मैं प्रतिक्रिया को मता था।\n\nOriginal: How are you?\nTranslated: तुम कैसे है?\n\nOriginal: This is a test sentence for translation.\nTranslated: यह ्तान के लिए प्रकार की जाी वर्षा होती\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test_sentence = ['who are you']\ninput = tokenizer(test_sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\ntranslated_token = model_test.generate(**input)\ntranslated_sentence = [tokenizer.decode(t, skip_special_tokens=True) for t in translated_token]\n# Print the results\nfor original, translated in zip(test_sentence, translated_sentence):\n    print(f\"Original: {original}\")\n    print(f\"Translated: {translated}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:41:35.097155Z","iopub.execute_input":"2024-06-03T16:41:35.097557Z","iopub.status.idle":"2024-06-03T16:41:35.668774Z","shell.execute_reply.started":"2024-06-03T16:41:35.097530Z","shell.execute_reply":"2024-06-03T16:41:35.667871Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Original: who are you\nTranslated: तुम वास् हैं\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# download model ","metadata":{}},{"cell_type":"code","source":"import shutil\nfrom IPython.display import FileLink\n\n# Path to the folder you want to zip\nfolder_to_zip = '/kaggle/working/fine-tuned-marianmt-en-hi'\n# Path for the output zip file\noutput_zip = '/kaggle/working/fine-tuned-marianmt-en-hi.zip'\n\n# Zip the folder\nshutil.make_archive(output_zip.replace('.zip', ''), 'zip', folder_to_zip)\n\n# Display the download link\nFileLink(output_zip)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T16:17:44.953451Z","iopub.execute_input":"2024-06-03T16:17:44.953860Z","iopub.status.idle":"2024-06-03T16:18:02.337087Z","shell.execute_reply.started":"2024-06-03T16:17:44.953832Z","shell.execute_reply":"2024-06-03T16:18:02.335695Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/fine-tuned-marianmt-en-hi.zip","text/html":"<a href='/kaggle/working/fine-tuned-marianmt-en-hi.zip' target='_blank'>/kaggle/working/fine-tuned-marianmt-en-hi.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}